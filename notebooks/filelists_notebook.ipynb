{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/halechr/repos/PhoGlobusHelpers/filelists/GreatGDriveMigration2023/dirsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023-09-12 - New Filelist Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_file: /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/Rachel_dirsize.csv\n",
      "\tRachel\n",
      "\tData/Rachel\n",
      "a_file: /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/Nat_dirsize.csv\n",
      "\tNat\n",
      "\tData/Nat\n",
      "a_file: /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/Utku_dirsize.csv\n",
      "\tUtku\n",
      "\tData/Utku\n",
      "a_file: /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/Laurel_dirsize.csv\n",
      "\tLaurel\n",
      "\tData/Laurel\n",
      "encountered parser error for /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/Laurel_dirsize.csv\n",
      "a_file: /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/Kourosh_dirsize.csv\n",
      "\tKourosh\n",
      "\tData/Kourosh\n",
      "a_file: /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/Bapun_dirsize.csv\n",
      "\tBapun\n",
      "\tData/Bapun\n",
      "a_file: /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/Jahngir_dirsize.csv\n",
      "\tJahngir\n",
      "\tData/Jahngir\n",
      "a_file: /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/Hiro_dirsize.csv\n",
      "\tHiro\n",
      "\tData/Hiro\n",
      "a_file: /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/KDIBA_dirsize.csv\n",
      "\tKDIBA\n",
      "\tData/KDIBA\n",
      "a_file: /home/halechr/Desktop/GreatGDriveMigration2023/dirsize/Output_dirsize.csv\n",
      "\tOutput\n",
      "\tData/Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>modified_dt</th>\n",
       "      <th>size_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/Rachel/Take 2021-11-24 11.23.05 AM.csv</td>\n",
       "      <td>2022-08-11 12:41:13</td>\n",
       "      <td>1888355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/Rachel/Take 2021-11-24 11.13.41 AM.csv</td>\n",
       "      <td>2022-08-11 12:40:48</td>\n",
       "      <td>731099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/Rachel/Take 2021-11-24 11.12.49 AM.csv</td>\n",
       "      <td>2022-08-11 12:39:44</td>\n",
       "      <td>13590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/Rachel/Take 2021-08-27 12.59.15 PM.tak</td>\n",
       "      <td>2022-02-25 13:09:10</td>\n",
       "      <td>10307644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/Rachel/Take 2021-11-24 11.34.03 AM.tak</td>\n",
       "      <td>2022-02-25 13:00:58</td>\n",
       "      <td>262879235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...</td>\n",
       "      <td>2023-06-01 02:09:10</td>\n",
       "      <td>537957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...</td>\n",
       "      <td>2023-06-01 02:09:08</td>\n",
       "      <td>748944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...</td>\n",
       "      <td>2023-06-01 02:09:03</td>\n",
       "      <td>735368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...</td>\n",
       "      <td>2023-06-01 02:08:58</td>\n",
       "      <td>500886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...</td>\n",
       "      <td>2023-06-01 02:08:55</td>\n",
       "      <td>472432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120589 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name          modified_dt  \\\n",
       "0          Data/Rachel/Take 2021-11-24 11.23.05 AM.csv  2022-08-11 12:41:13   \n",
       "1          Data/Rachel/Take 2021-11-24 11.13.41 AM.csv  2022-08-11 12:40:48   \n",
       "2          Data/Rachel/Take 2021-11-24 11.12.49 AM.csv  2022-08-11 12:39:44   \n",
       "3          Data/Rachel/Take 2021-08-27 12.59.15 PM.tak  2022-02-25 13:09:10   \n",
       "4          Data/Rachel/Take 2021-11-24 11.34.03 AM.tak  2022-02-25 13:00:58   \n",
       "..                                                 ...                  ...   \n",
       "690  Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...  2023-06-01 02:09:10   \n",
       "691  Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...  2023-06-01 02:09:08   \n",
       "692  Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...  2023-06-01 02:09:03   \n",
       "693  Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...  2023-06-01 02:08:58   \n",
       "694  Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...  2023-06-01 02:08:55   \n",
       "\n",
       "     size_bytes  \n",
       "0       1888355  \n",
       "1        731099  \n",
       "2         13590  \n",
       "3      10307644  \n",
       "4     262879235  \n",
       "..          ...  \n",
       "690      537957  \n",
       "691      748944  \n",
       "692      735368  \n",
       "693      500886  \n",
       "694      472432  \n",
       "\n",
       "[120589 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def chunk_dataframe(df, size_limit_bytes):\n",
    "    \"\"\"\n",
    "    Splits the dataframe into chunks based on a cumulative size in 'size_bytes' column.\n",
    "\n",
    "    :param df: DataFrame to split\n",
    "    :param size_limit_bytes: Max size for each chunk in bytes\n",
    "    :return: List of dataframes\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_chunk_size = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if current_chunk_size + row['size_bytes'] > size_limit_bytes:\n",
    "            chunks.append(pd.DataFrame(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_chunk_size = 0\n",
    "\n",
    "        current_chunk.append(row)\n",
    "        current_chunk_size += row['size_bytes']\n",
    "\n",
    "    # Append any remaining data\n",
    "    if current_chunk:\n",
    "        chunks.append(pd.DataFrame(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def convert_filelist_to_new_parent(filelist_source: List[Path], original_parent_path: Path = Path(r'/media/MAX/cloud/turbo/Data'), dest_parent_path: Path = Path(r'/media/MAX/Data')):\n",
    "    \"\"\" Converts a list of file paths from their current parent, specified by `original_parent_path`, to their new parent `dest_parent_path` \"\"\"\n",
    "    filelist_dest = []\n",
    "    for path in filelist_source:\n",
    "        relative_path = str(path.relative_to(original_parent_path))\n",
    "        new_path = Path(dest_parent_path) / relative_path\n",
    "        filelist_dest.append(new_path)\n",
    "    return filelist_dest\n",
    "\n",
    "# Load filelist from disk\n",
    "# active_filelist_path = Path('/home/halechr/repo/PhoGlobusHelpers/filelists/session_results_filelist_2023-07-12.csv').resolve()\n",
    "# active_filelist_path = Path('/home/halechr/repos/PhoGlobusHelpers/filelists/GreatGDriveMigration2023/dirsize/Bapun_dirsize.csv').resolve()\n",
    "active_root_filelist_parent_path = Path('/home/halechr/Desktop/GreatGDriveMigration2023/dirsize').resolve()\n",
    "active_filelist_files = active_root_filelist_parent_path.glob('*.csv')\n",
    "filelist_dfs_list = []\n",
    "filelists_list = []\n",
    "for a_file in active_filelist_files:\n",
    "    print(f'a_file: {a_file}')\n",
    "    active_filelist_path = Path(a_file).resolve()\n",
    "    try:\n",
    "        user, filename_suffix = active_filelist_path.name.split('_')\n",
    "        print(f'\\t{user}')\n",
    "        parent_user_folder = Path(f\"Data/{user}\")\n",
    "        print(f'\\t{parent_user_folder}')\n",
    "        filelist_df = pd.read_csv(active_filelist_path, header=0, names=[\"name\", \"modified_dt\", \"size_bytes\"])\n",
    "        all_files_list = [parent_user_folder.joinpath(_a_file) for _a_file in filelist_df[\"name\"]]\n",
    "        filelist_df['name'] = all_files_list\n",
    "        filelist_dfs_list.append(filelist_df)\n",
    "        filelists_list.append(all_files_list)\n",
    "    except pd.errors.ParserError:\n",
    "        print(f'encountered parser error for {active_filelist_path}')\n",
    "    except BaseException:\n",
    "        raise\n",
    "\n",
    "combined_filelist_df = pd.concat(filelist_dfs_list)\n",
    "combined_filelist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65467.555576481"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_all_files_num_GB = combined_filelist_df.size_bytes.sum()/1e9\n",
    "total_all_files_num_GB # 65467.555576481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_limit = 750e9  # 750GB in bytes\n",
    "size_limit = 3999e9  # 4TB in bytes\n",
    "chunks = chunk_dataframe(combined_filelist_df, size_limit)\n",
    "num_chunks = len(chunks)\n",
    "print(f'num_chunks: {num_chunks}')\n",
    "# for chunk in chunks:\n",
    "#     print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>modified_dt</th>\n",
       "      <th>size_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/Rachel/Take 2021-11-24 11.23.05 AM.csv</td>\n",
       "      <td>2022-08-11 12:41:13</td>\n",
       "      <td>1888355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/Rachel/Take 2021-11-24 11.13.41 AM.csv</td>\n",
       "      <td>2022-08-11 12:40:48</td>\n",
       "      <td>731099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/Rachel/Take 2021-11-24 11.12.49 AM.csv</td>\n",
       "      <td>2022-08-11 12:39:44</td>\n",
       "      <td>13590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/Rachel/Take 2021-08-27 12.59.15 PM.tak</td>\n",
       "      <td>2022-02-25 13:09:10</td>\n",
       "      <td>10307644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/Rachel/Take 2021-11-24 11.34.03 AM.tak</td>\n",
       "      <td>2022-02-25 13:00:58</td>\n",
       "      <td>262879235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...</td>\n",
       "      <td>2023-06-01 02:09:10</td>\n",
       "      <td>537957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...</td>\n",
       "      <td>2023-06-01 02:09:08</td>\n",
       "      <td>748944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...</td>\n",
       "      <td>2023-06-01 02:09:03</td>\n",
       "      <td>735368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...</td>\n",
       "      <td>2023-06-01 02:08:58</td>\n",
       "      <td>500886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...</td>\n",
       "      <td>2023-06-01 02:08:55</td>\n",
       "      <td>472432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120589 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name          modified_dt  \\\n",
       "0          Data/Rachel/Take 2021-11-24 11.23.05 AM.csv  2022-08-11 12:41:13   \n",
       "1          Data/Rachel/Take 2021-11-24 11.13.41 AM.csv  2022-08-11 12:40:48   \n",
       "2          Data/Rachel/Take 2021-11-24 11.12.49 AM.csv  2022-08-11 12:39:44   \n",
       "3          Data/Rachel/Take 2021-08-27 12.59.15 PM.tak  2022-02-25 13:09:10   \n",
       "4          Data/Rachel/Take 2021-11-24 11.34.03 AM.tak  2022-02-25 13:00:58   \n",
       "..                                                 ...                  ...   \n",
       "690  Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...  2023-06-01 02:09:10   \n",
       "691  Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...  2023-06-01 02:09:08   \n",
       "692  Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...  2023-06-01 02:09:03   \n",
       "693  Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...  2023-06-01 02:08:58   \n",
       "694  Data/Output/2023-06-01/kdiba/vvp01/two/2006-4-...  2023-06-01 02:08:55   \n",
       "\n",
       "     size_bytes  \n",
       "0       1888355  \n",
       "1        731099  \n",
       "2         13590  \n",
       "3      10307644  \n",
       "4     262879235  \n",
       "..          ...  \n",
       "690      537957  \n",
       "691      748944  \n",
       "692      735368  \n",
       "693      500886  \n",
       "694      472432  \n",
       "\n",
       "[120589 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filelist_df = pd.read_csv(active_filelist_path, header=0, names=[\"name\", \"modified_dt\", \"size_bytes\"])\n",
    "filelist_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21955757.33845806"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(filelist_df['size_bytes']/(1024.0 * 1024.0)) # Convert to GigaBytes (GB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name           object\n",
       "modified_dt    object\n",
       "size_bytes      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_source = [Path(a_path_str).resolve() for a_path_str in filelist_df.Path]\n",
    "\n",
    "\n",
    "\n",
    "source_parent_path = Path(r'/media/MAX/cloud/turbo/Data')\n",
    "dest_parent_path = Path(r'/media/MAX/Data')\n",
    "# # Build the destination filelist from the source_filelist and the two paths:\n",
    "filelist_dest = convert_filelist_to_new_parent(filelist_source, original_parent_path=source_parent_path, dest_parent_path=dest_parent_path)\n",
    "filelist_dest\n",
    "\n",
    "# filelist_source\n",
    "# filelist_dest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
